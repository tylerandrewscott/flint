{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n"
     ]
    }
   ],
   "source": [
    "#This code scrapes dca site to create dataframe of local government authorities\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import html5lib as h5\n",
    "import bs4\n",
    "\n",
    "profile = webdriver.FirefoxProfile()\n",
    "profile.set_preference(\"general.useragent.override\",\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.111 Safari/537.36\")\n",
    "driver = webdriver.Firefox(profile)\n",
    "\n",
    "\n",
    "bases = [\n",
    "#4/2011\n",
    "'https://web.archive.org/web/20110402011728/http://www.gmanet.com/Cities.aspx?',\n",
    "#1/2012\n",
    "'https://web.archive.org/web/20120111121556/http://www.gmanet.com/cities.aspx?',\n",
    "#1/2013\n",
    "'https://web.archive.org/web/20130126202452/http://www.gmanet.com/Cities.aspx?',\n",
    "#2/2014        \n",
    "'https://web.archive.org/web/20140216232911/http://www.gmanet.com/Cities.aspx',\n",
    "#1/2015\n",
    "'https://web.archive.org/web/20150112061115/http://www.gmanet.com/Cities.aspx'] \n",
    "\n",
    "letterlist = ['A-C','D-J','K-N','O-R','S-Z']\n",
    "linkdf = pd.DataFrame(columns=('Link','Name','Year'))\n",
    "\n",
    "\n",
    "#### READ 2011 CITY LINKS #####\n",
    "print(2011)\n",
    "driver.get(bases[0])\n",
    "for letters in letterlist:\n",
    "    driver.find_element_by_link_text(letters).click()\n",
    "    temp = driver.find_elements_by_css_selector('.CityListLink')\n",
    "    templinks = []\n",
    "    tempnames = []\n",
    "    for i in temp:\n",
    "        templinks.append(i.get_attribute('href'))\n",
    "        tempnames.append(i.get_attribute('text'))\n",
    "    tempdf = pd.DataFrame(templinks,columns=['Link'])\n",
    "    tempdf['Name'] = tempnames\n",
    "    tempdf['Year'] = '2011'\n",
    "linkdf = linkdf.append(tempdf)         \n",
    "print(2012)\n",
    "#### READ 2012 CITY LINKS #####\n",
    "driver.get(bases[1])\n",
    "for citylist in range(1,6):\n",
    "    temp = driver.find_elements_by_css_selector('#ctl00_MainContent_uxCityList_dlCityList'+str(citylist)+' a')\n",
    "    templinks = []\n",
    "    tempnames = []\n",
    "    for i in temp:\n",
    "        templinks.append(i.get_attribute('href'))\n",
    "        tempnames.append(i.get_attribute('text'))\n",
    "    tempdf = pd.DataFrame(templinks,columns=['Link'])\n",
    "    tempdf['Name'] = tempnames\n",
    "    tempdf['Year'] = '2012'\n",
    "    linkdf = linkdf.append(tempdf)  \n",
    "        \n",
    "#### READ 2013 CITY LINKS ##### \n",
    "print(2013)\n",
    "driver.get(bases[2])\n",
    "for citylist in range(1,6):\n",
    "    temp = driver.find_elements_by_css_selector('#ctl00_MainContent_uxCityList_dlCityList'+str(citylist)+' a')\n",
    "    templinks = []\n",
    "    tempnames = []\n",
    "    for i in temp:\n",
    "        templinks.append(i.get_attribute('href'))\n",
    "        tempnames.append(i.get_attribute('text'))\n",
    "    tempdf = pd.DataFrame(templinks,columns=['Link'])\n",
    "    tempdf['Name'] = tempnames\n",
    "    tempdf['Year'] = '2013'\n",
    "    linkdf = linkdf.append(tempdf) \n",
    "        \n",
    "#### READ 2014 CITY LINKS #####  \n",
    "print(2014)\n",
    "driver.get(bases[3])\n",
    "for citylist in range(1,6):\n",
    "    temp = driver.find_elements_by_css_selector('#ctl00_MainContent_uxCityList_dlCityList'+str(citylist)+' a')\n",
    "    templinks = []\n",
    "    tempnames = []\n",
    "    for i in temp:\n",
    "        templinks.append(i.get_attribute('href'))\n",
    "        tempnames.append(i.get_attribute('text'))\n",
    "    tempdf = pd.DataFrame(templinks,columns=['Link'])\n",
    "    tempdf['Name'] = tempnames\n",
    "    tempdf['Year'] = '2014'\n",
    "    linkdf = linkdf.append(tempdf) \n",
    "\n",
    "#### READ 2015 CITY LINKS ##### \n",
    "print(2015)\n",
    "driver.get(bases[4])\n",
    "temp = driver.find_elements_by_css_selector('.ui-corner-bottom a')\n",
    "templinks = []\n",
    "tempnames = []\n",
    "for i in temp:\n",
    "    templinks.append(i.get_attribute('href'))\n",
    "    tempnames.append(i.get_attribute('text'))\n",
    "tempdf = pd.DataFrame(templinks,columns=['Link'])\n",
    "tempdf['Name'] = tempnames\n",
    "tempdf['Year'] = '2015'\n",
    "linkdf = linkdf.append(tempdf)\n",
    "#linkdf.to_csv(path_or_buf = '../../Input/officials.data/ga.city.links.2011.2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "citydf = pd.DataFrame(columns=['Name','Title','Year','City','Link'])\n",
    "#for ll in range(0,10):\n",
    "for ll in range(linkdf.shape[0]):\n",
    "    f = requests.get(linkdf['Link'].iloc[ll])\n",
    "    citysoup = BeautifulSoup(f.text,'html.parser')\n",
    "    if '2011' or '2012' == linkdf['Year'].iloc[ll]:\n",
    "        citytable = citysoup.select('.TableCell')\n",
    "        namelist = []\n",
    "        titlelist = []\n",
    "        for nnode in citysoup.findAll(attrs={'id': re.compile('lblName')}):\n",
    "            namelist.append(nnode.text)\n",
    "        for tnode in citysoup.findAll(attrs={'id': re.compile('lblTitle')}):\n",
    "            titlelist.append(tnode.text)\n",
    "        tempcitydf = pd.DataFrame({'Title' : titlelist,'Name' : namelist})\n",
    "        tempcitydf['Year'] = linkdf['Year'].iloc[ll]\n",
    "        tempcitydf['City'] = linkdf['Name'].iloc[ll]\n",
    "        tempcitydf['Link'] = linkdf['Link'].iloc[ll]\n",
    "        citydf = citydf.append(tempcitydf)\n",
    "    if '2011' or '2012' != linkdf['Year'].iloc[ll]:\n",
    "        citytable = citysoup.select('.OfficialsColumnItem span')\n",
    "        namelist = []\n",
    "        titlelist = []\n",
    "        for nnode in citysoup.findAll(attrs={'id': re.compile('uxName')}):\n",
    "            namelist.append(nnode.text)\n",
    "        for tnode in citysoup.findAll(attrs={'id': re.compile('uxTitle')}):\n",
    "            titlelist.append(tnode.text)\n",
    "        tempcitydf = pd.DataFrame({'Title' : titlelist,'Name' : namelist})\n",
    "        tempcitydf['Year'] = linkdf['Year'].iloc[ll]\n",
    "        tempcitydf['City'] = linkdf['Name'].iloc[ll]\n",
    "        tempcitydf['Link'] = linkdf['Link'].iloc[ll]\n",
    "        citydf = citydf.append(tempcitydf)\n",
    "    if ll % 500 == 0:\n",
    "        print(ll)\n",
    "    #citydf.to_csv(path_or_buf = '../../Input/ga.city.officials.2011.2015.csv')\n",
    "#citydf.to_csv(path_or_buf = '../../Input/ga.city.officials.2011.2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citydf.to_csv(path_or_buf = '../../Input/officials.data/ga.city.officials.2011.2015.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
